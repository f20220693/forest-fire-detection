{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f386ccf7-c727-42b4-97e3-a52c188b3991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.20.0-cp313-cp313-win_amd64.whl.metadata (4.6 kB)\n",
      "Collecting tensorflow_hub\n",
      "  Downloading tensorflow_hub-0.16.1-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting librosa\n",
      "  Downloading librosa-0.11.0-py3-none-any.whl.metadata (8.7 kB)\n",
      "Collecting soundfile\n",
      "  Downloading soundfile-0.13.1-py2.py3-none-win_amd64.whl.metadata (16 kB)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\mrutyunjaya em\\anaconda3\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\mrutyunjaya em\\anaconda3\\lib\\site-packages (3.10.0)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow)\n",
      "  Downloading absl_py-2.3.1-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
      "  Downloading flatbuffers-25.9.23-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google_pasta>=0.1.1 (from tensorflow)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting opt_einsum>=2.3.2 (from tensorflow)\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\mrutyunjaya em\\anaconda3\\lib\\site-packages (from tensorflow) (24.2)\n",
      "Requirement already satisfied: protobuf>=5.28.0 in c:\\users\\mrutyunjaya em\\anaconda3\\lib\\site-packages (from tensorflow) (5.29.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\mrutyunjaya em\\anaconda3\\lib\\site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\mrutyunjaya em\\anaconda3\\lib\\site-packages (from tensorflow) (72.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\mrutyunjaya em\\anaconda3\\lib\\site-packages (from tensorflow) (1.17.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Downloading termcolor-3.2.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in c:\\users\\mrutyunjaya em\\anaconda3\\lib\\site-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\mrutyunjaya em\\anaconda3\\lib\\site-packages (from tensorflow) (1.17.0)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Downloading grpcio-1.76.0-cp313-cp313-win_amd64.whl.metadata (3.8 kB)\n",
      "Collecting tensorboard~=2.20.0 (from tensorflow)\n",
      "  Downloading tensorboard-2.20.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting keras>=3.10.0 (from tensorflow)\n",
      "  Downloading keras-3.12.0-py3-none-any.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\mrutyunjaya em\\anaconda3\\lib\\site-packages (from tensorflow) (2.1.3)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\mrutyunjaya em\\anaconda3\\lib\\site-packages (from tensorflow) (3.12.1)\n",
      "Collecting ml_dtypes<1.0.0,>=0.5.1 (from tensorflow)\n",
      "  Downloading ml_dtypes-0.5.3-cp313-cp313-win_amd64.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\mrutyunjaya em\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mrutyunjaya em\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\mrutyunjaya em\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mrutyunjaya em\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2025.4.26)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\mrutyunjaya em\\anaconda3\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (3.8)\n",
      "Requirement already satisfied: pillow in c:\\users\\mrutyunjaya em\\anaconda3\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (11.1.0)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard~=2.20.0->tensorflow)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\mrutyunjaya em\\anaconda3\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (3.1.3)\n",
      "Collecting tf-keras>=2.14.1 (from tensorflow_hub)\n",
      "  Downloading tf_keras-2.20.1-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting audioread>=2.1.9 (from librosa)\n",
      "  Downloading audioread-3.1.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: numba>=0.51.0 in c:\\users\\mrutyunjaya em\\anaconda3\\lib\\site-packages (from librosa) (0.61.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\mrutyunjaya em\\anaconda3\\lib\\site-packages (from librosa) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.0 in c:\\users\\mrutyunjaya em\\anaconda3\\lib\\site-packages (from librosa) (1.4.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\mrutyunjaya em\\anaconda3\\lib\\site-packages (from librosa) (5.1.1)\n",
      "Collecting pooch>=1.1 (from librosa)\n",
      "  Downloading pooch-1.8.2-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting soxr>=0.3.2 (from librosa)\n",
      "  Downloading soxr-1.0.0-cp312-abi3-win_amd64.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: lazy_loader>=0.1 in c:\\users\\mrutyunjaya em\\anaconda3\\lib\\site-packages (from librosa) (0.4)\n",
      "Requirement already satisfied: msgpack>=1.0 in c:\\users\\mrutyunjaya em\\anaconda3\\lib\\site-packages (from librosa) (1.0.3)\n",
      "Collecting standard-aifc (from librosa)\n",
      "  Downloading standard_aifc-3.13.0-py3-none-any.whl.metadata (969 bytes)\n",
      "Collecting standard-sunau (from librosa)\n",
      "  Downloading standard_sunau-3.13.0-py3-none-any.whl.metadata (914 bytes)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\users\\mrutyunjaya em\\anaconda3\\lib\\site-packages (from soundfile) (1.17.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\mrutyunjaya em\\anaconda3\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\mrutyunjaya em\\anaconda3\\lib\\site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\mrutyunjaya em\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\mrutyunjaya em\\anaconda3\\lib\\site-packages (from matplotlib) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\mrutyunjaya em\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\mrutyunjaya em\\anaconda3\\lib\\site-packages (from matplotlib) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\mrutyunjaya em\\anaconda3\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\mrutyunjaya em\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\mrutyunjaya em\\anaconda3\\lib\\site-packages (from cffi>=1.0->soundfile) (2.21)\n",
      "Requirement already satisfied: rich in c:\\users\\mrutyunjaya em\\anaconda3\\lib\\site-packages (from keras>=3.10.0->tensorflow) (13.9.4)\n",
      "Collecting namex (from keras>=3.10.0->tensorflow)\n",
      "  Downloading namex-0.1.0-py3-none-any.whl.metadata (322 bytes)\n",
      "Collecting optree (from keras>=3.10.0->tensorflow)\n",
      "  Downloading optree-0.18.0-cp313-cp313-win_amd64.whl.metadata (35 kB)\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in c:\\users\\mrutyunjaya em\\anaconda3\\lib\\site-packages (from numba>=0.51.0->librosa) (0.44.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in c:\\users\\mrutyunjaya em\\anaconda3\\lib\\site-packages (from pooch>=1.1->librosa) (4.3.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\mrutyunjaya em\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\mrutyunjaya em\\anaconda3\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\mrutyunjaya em\\anaconda3\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\mrutyunjaya em\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow) (0.1.0)\n",
      "Collecting standard-chunk (from standard-aifc->librosa)\n",
      "  Downloading standard_chunk-3.13.0-py3-none-any.whl.metadata (860 bytes)\n",
      "Collecting audioop-lts (from standard-aifc->librosa)\n",
      "  Downloading audioop_lts-0.2.2-cp313-abi3-win_amd64.whl.metadata (2.0 kB)\n",
      "Downloading tensorflow-2.20.0-cp313-cp313-win_amd64.whl (332.0 MB)\n",
      "   ---------------------------------------- 0.0/332.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.0/332.0 MB 5.2 MB/s eta 0:01:04\n",
      "   ---------------------------------------- 2.9/332.0 MB 6.9 MB/s eta 0:00:48\n",
      "    --------------------------------------- 4.5/332.0 MB 7.3 MB/s eta 0:00:45\n",
      "    --------------------------------------- 6.3/332.0 MB 7.6 MB/s eta 0:00:43\n",
      "    --------------------------------------- 7.6/332.0 MB 7.8 MB/s eta 0:00:42\n",
      "   - -------------------------------------- 9.2/332.0 MB 7.5 MB/s eta 0:00:44\n",
      "   - -------------------------------------- 10.7/332.0 MB 7.5 MB/s eta 0:00:43\n",
      "   - -------------------------------------- 14.2/332.0 MB 8.5 MB/s eta 0:00:38\n",
      "   -- ------------------------------------- 17.8/332.0 MB 9.5 MB/s eta 0:00:33\n",
      "   -- ------------------------------------- 21.0/332.0 MB 10.2 MB/s eta 0:00:31\n",
      "   -- ------------------------------------- 24.6/332.0 MB 10.8 MB/s eta 0:00:29\n",
      "   --- ------------------------------------ 26.2/332.0 MB 10.9 MB/s eta 0:00:29\n",
      "   --- ------------------------------------ 28.6/332.0 MB 10.6 MB/s eta 0:00:29\n",
      "   --- ------------------------------------ 31.7/332.0 MB 11.0 MB/s eta 0:00:28\n",
      "   --- ------------------------------------ 33.0/332.0 MB 10.6 MB/s eta 0:00:29\n",
      "   ---- ----------------------------------- 33.8/332.0 MB 10.6 MB/s eta 0:00:29\n",
      "   ---- ----------------------------------- 35.1/332.0 MB 10.0 MB/s eta 0:00:30\n",
      "   ---- ----------------------------------- 39.3/332.0 MB 10.6 MB/s eta 0:00:28\n",
      "   ----- ---------------------------------- 41.9/332.0 MB 10.7 MB/s eta 0:00:28\n",
      "   ----- ---------------------------------- 45.4/332.0 MB 11.0 MB/s eta 0:00:27\n",
      "   ----- ---------------------------------- 47.7/332.0 MB 11.1 MB/s eta 0:00:26\n",
      "   ----- ---------------------------------- 48.2/332.0 MB 11.1 MB/s eta 0:00:26\n",
      "   ------ --------------------------------- 50.6/332.0 MB 10.7 MB/s eta 0:00:27\n",
      "   ------ --------------------------------- 54.3/332.0 MB 11.0 MB/s eta 0:00:26\n",
      "   ------- -------------------------------- 61.1/332.0 MB 11.9 MB/s eta 0:00:23\n",
      "   -------- ------------------------------- 69.2/332.0 MB 12.9 MB/s eta 0:00:21\n",
      "   --------- ------------------------------ 77.3/332.0 MB 13.9 MB/s eta 0:00:19\n",
      "   ---------- ----------------------------- 84.9/332.0 MB 14.8 MB/s eta 0:00:17\n",
      "   ---------- ----------------------------- 90.4/332.0 MB 15.2 MB/s eta 0:00:16\n",
      "   ----------- ---------------------------- 96.2/332.0 MB 15.6 MB/s eta 0:00:16\n",
      "   ----------- --------------------------- 101.2/332.0 MB 15.9 MB/s eta 0:00:15\n",
      "   ------------ -------------------------- 105.4/332.0 MB 16.1 MB/s eta 0:00:15\n",
      "   ------------ -------------------------- 108.5/332.0 MB 16.0 MB/s eta 0:00:14\n",
      "   ------------- ------------------------- 113.8/332.0 MB 16.3 MB/s eta 0:00:14\n",
      "   ------------- ------------------------- 116.7/332.0 MB 16.2 MB/s eta 0:00:14\n",
      "   ------------- ------------------------- 118.2/332.0 MB 16.1 MB/s eta 0:00:14\n",
      "   -------------- ------------------------ 120.1/332.0 MB 15.8 MB/s eta 0:00:14\n",
      "   -------------- ------------------------ 121.4/332.0 MB 15.6 MB/s eta 0:00:14\n",
      "   -------------- ------------------------ 121.4/332.0 MB 15.6 MB/s eta 0:00:14\n",
      "   -------------- ------------------------ 122.2/332.0 MB 14.9 MB/s eta 0:00:15\n",
      "   -------------- ------------------------ 122.9/332.0 MB 14.7 MB/s eta 0:00:15\n",
      "   -------------- ------------------------ 123.5/332.0 MB 14.3 MB/s eta 0:00:15\n",
      "   -------------- ------------------------ 124.5/332.0 MB 14.1 MB/s eta 0:00:15\n",
      "   -------------- ------------------------ 125.0/332.0 MB 13.8 MB/s eta 0:00:15\n",
      "   -------------- ------------------------ 125.8/332.0 MB 13.7 MB/s eta 0:00:16\n",
      "   --------------- ----------------------- 128.2/332.0 MB 13.5 MB/s eta 0:00:16\n",
      "   --------------- ----------------------- 132.1/332.0 MB 13.6 MB/s eta 0:00:15\n",
      "   --------------- ----------------------- 135.8/332.0 MB 13.7 MB/s eta 0:00:15\n",
      "   ---------------- ---------------------- 140.5/332.0 MB 13.9 MB/s eta 0:00:14\n",
      "   ----------------- --------------------- 148.1/332.0 MB 14.4 MB/s eta 0:00:13\n",
      "   ------------------ -------------------- 156.2/332.0 MB 14.9 MB/s eta 0:00:12\n",
      "   ------------------ -------------------- 157.8/332.0 MB 14.7 MB/s eta 0:00:12\n",
      "   ------------------ -------------------- 159.6/332.0 MB 14.6 MB/s eta 0:00:12\n",
      "   ------------------- ------------------- 162.0/332.0 MB 14.6 MB/s eta 0:00:12\n",
      "   ------------------- ------------------- 166.2/332.0 MB 14.7 MB/s eta 0:00:12\n",
      "   -------------------- ------------------ 170.7/332.0 MB 14.8 MB/s eta 0:00:11\n",
      "   -------------------- ------------------ 178.0/332.0 MB 15.1 MB/s eta 0:00:11\n",
      "   --------------------- ----------------- 181.7/332.0 MB 15.2 MB/s eta 0:00:10\n",
      "   --------------------- ----------------- 185.6/332.0 MB 15.3 MB/s eta 0:00:10\n",
      "   ---------------------- ---------------- 188.7/332.0 MB 15.3 MB/s eta 0:00:10\n",
      "   ---------------------- ---------------- 191.4/332.0 MB 15.2 MB/s eta 0:00:10\n",
      "   ----------------------- --------------- 197.7/332.0 MB 15.4 MB/s eta 0:00:09\n",
      "   ------------------------ -------------- 207.1/332.0 MB 15.9 MB/s eta 0:00:08\n",
      "   ------------------------- ------------- 218.1/332.0 MB 16.5 MB/s eta 0:00:07\n",
      "   -------------------------- ------------ 224.4/332.0 MB 16.7 MB/s eta 0:00:07\n",
      "   --------------------------- ----------- 230.9/332.0 MB 17.0 MB/s eta 0:00:06\n",
      "   ---------------------------- ---------- 240.4/332.0 MB 17.4 MB/s eta 0:00:06\n",
      "   ---------------------------- ---------- 243.5/332.0 MB 17.4 MB/s eta 0:00:06\n",
      "   ---------------------------- ---------- 245.4/332.0 MB 17.3 MB/s eta 0:00:06\n",
      "   ----------------------------- --------- 247.2/332.0 MB 17.1 MB/s eta 0:00:05\n",
      "   ----------------------------- --------- 251.1/332.0 MB 17.1 MB/s eta 0:00:05\n",
      "   ------------------------------ -------- 257.9/332.0 MB 17.3 MB/s eta 0:00:05\n",
      "   ------------------------------ -------- 263.5/332.0 MB 17.7 MB/s eta 0:00:04\n",
      "   ------------------------------- ------- 268.7/332.0 MB 18.1 MB/s eta 0:00:04\n",
      "   ------------------------------- ------- 272.1/332.0 MB 18.5 MB/s eta 0:00:04\n",
      "   -------------------------------- ------ 275.5/332.0 MB 18.6 MB/s eta 0:00:04\n",
      "   -------------------------------- ------ 277.1/332.0 MB 18.5 MB/s eta 0:00:03\n",
      "   --------------------------------- ----- 281.3/332.0 MB 18.5 MB/s eta 0:00:03\n",
      "   --------------------------------- ----- 282.9/332.0 MB 18.4 MB/s eta 0:00:03\n",
      "   --------------------------------- ----- 285.5/332.0 MB 18.3 MB/s eta 0:00:03\n",
      "   --------------------------------- ----- 289.1/332.0 MB 18.5 MB/s eta 0:00:03\n",
      "   ---------------------------------- ---- 292.3/332.0 MB 18.5 MB/s eta 0:00:03\n",
      "   ---------------------------------- ---- 295.2/332.0 MB 18.7 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 298.1/332.0 MB 19.0 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 302.3/332.0 MB 19.0 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 307.0/332.0 MB 19.1 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 312.2/332.0 MB 19.7 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 313.5/332.0 MB 19.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 313.8/332.0 MB 19.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 314.3/332.0 MB 19.0 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 314.3/332.0 MB 19.0 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 314.6/332.0 MB 18.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 315.4/332.0 MB 18.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 316.4/332.0 MB 18.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 317.7/332.0 MB 17.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 318.8/332.0 MB 17.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 319.8/332.0 MB 17.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 323.2/332.0 MB 17.3 MB/s eta 0:00:01\n",
      "   --------------------------------------  326.6/332.0 MB 17.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  330.3/332.0 MB 17.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  331.9/332.0 MB 17.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  331.9/332.0 MB 17.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  331.9/332.0 MB 17.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  331.9/332.0 MB 17.0 MB/s eta 0:00:01\n",
      "   --------------------------------------- 332.0/332.0 MB 16.1 MB/s eta 0:00:00\n",
      "Downloading grpcio-1.76.0-cp313-cp313-win_amd64.whl (4.7 MB)\n",
      "   ---------------------------------------- 0.0/4.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 4.7/4.7 MB 26.3 MB/s eta 0:00:00\n",
      "Downloading ml_dtypes-0.5.3-cp313-cp313-win_amd64.whl (208 kB)\n",
      "Downloading tensorboard-2.20.0-py3-none-any.whl (5.5 MB)\n",
      "   ---------------------------------------- 0.0/5.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 5.5/5.5 MB 29.4 MB/s eta 0:00:00\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Downloading tensorflow_hub-0.16.1-py2.py3-none-any.whl (30 kB)\n",
      "Downloading librosa-0.11.0-py3-none-any.whl (260 kB)\n",
      "Downloading soundfile-0.13.1-py2.py3-none-win_amd64.whl (1.0 MB)\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.0/1.0 MB 17.8 MB/s eta 0:00:00\n",
      "Downloading absl_py-2.3.1-py3-none-any.whl (135 kB)\n",
      "Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading audioread-3.1.0-py3-none-any.whl (23 kB)\n",
      "Downloading flatbuffers-25.9.23-py2.py3-none-any.whl (30 kB)\n",
      "Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading keras-3.12.0-py3-none-any.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.5/1.5 MB 13.1 MB/s eta 0:00:00\n",
      "Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
      "   ---------------------------------------- 0.0/26.4 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 3.9/26.4 MB 20.2 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 8.1/26.4 MB 20.3 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 14.4/26.4 MB 24.0 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 18.9/26.4 MB 22.9 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 22.8/26.4 MB 21.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.2/26.4 MB 22.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 26.4/26.4 MB 20.5 MB/s eta 0:00:00\n",
      "Downloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Downloading pooch-1.8.2-py3-none-any.whl (64 kB)\n",
      "Downloading soxr-1.0.0-cp312-abi3-win_amd64.whl (172 kB)\n",
      "Downloading termcolor-3.2.0-py3-none-any.whl (7.7 kB)\n",
      "Downloading tf_keras-2.20.1-py3-none-any.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.7/1.7 MB 14.3 MB/s eta 0:00:00\n",
      "Downloading namex-0.1.0-py3-none-any.whl (5.9 kB)\n",
      "Downloading optree-0.18.0-cp313-cp313-win_amd64.whl (314 kB)\n",
      "Downloading standard_aifc-3.13.0-py3-none-any.whl (10 kB)\n",
      "Downloading audioop_lts-0.2.2-cp313-abi3-win_amd64.whl (30 kB)\n",
      "Downloading standard_chunk-3.13.0-py3-none-any.whl (4.9 kB)\n",
      "Downloading standard_sunau-3.13.0-py3-none-any.whl (7.4 kB)\n",
      "Installing collected packages: standard-chunk, namex, libclang, flatbuffers, termcolor, tensorboard-data-server, soxr, optree, opt_einsum, ml_dtypes, grpcio, google_pasta, gast, audioop-lts, astunparse, absl-py, tensorboard, standard-sunau, standard-aifc, soundfile, pooch, keras, audioread, tensorflow, librosa, tf-keras, tensorflow_hub\n",
      "\n",
      "   -- -------------------------------------  2/27 [libclang]\n",
      "   -- -------------------------------------  2/27 [libclang]\n",
      "   -- -------------------------------------  2/27 [libclang]\n",
      "   ----- ----------------------------------  4/27 [termcolor]\n",
      "   ----------- ----------------------------  8/27 [opt_einsum]\n",
      "   ------------- --------------------------  9/27 [ml_dtypes]\n",
      "   -------------- ------------------------- 10/27 [grpcio]\n",
      "   -------------- ------------------------- 10/27 [grpcio]\n",
      "   ---------------- ----------------------- 11/27 [google_pasta]\n",
      "   ----------------- ---------------------- 12/27 [gast]\n",
      "   ---------------------- ----------------- 15/27 [absl-py]\n",
      "   ----------------------- ---------------- 16/27 [tensorboard]\n",
      "   ----------------------- ---------------- 16/27 [tensorboard]\n",
      "   ----------------------- ---------------- 16/27 [tensorboard]\n",
      "   ----------------------- ---------------- 16/27 [tensorboard]\n",
      "   ----------------------- ---------------- 16/27 [tensorboard]\n",
      "   ----------------------- ---------------- 16/27 [tensorboard]\n",
      "   ----------------------- ---------------- 16/27 [tensorboard]\n",
      "   ----------------------------- ---------- 20/27 [pooch]\n",
      "   ------------------------------- -------- 21/27 [keras]\n",
      "   ------------------------------- -------- 21/27 [keras]\n",
      "   ------------------------------- -------- 21/27 [keras]\n",
      "   ------------------------------- -------- 21/27 [keras]\n",
      "   ------------------------------- -------- 21/27 [keras]\n",
      "   ------------------------------- -------- 21/27 [keras]\n",
      "   ------------------------------- -------- 21/27 [keras]\n",
      "   ------------------------------- -------- 21/27 [keras]\n",
      "   ------------------------------- -------- 21/27 [keras]\n",
      "   ------------------------------- -------- 21/27 [keras]\n",
      "   ------------------------------- -------- 21/27 [keras]\n",
      "   ------------------------------- -------- 21/27 [keras]\n",
      "   ------------------------------- -------- 21/27 [keras]\n",
      "   ------------------------------- -------- 21/27 [keras]\n",
      "   ------------------------------- -------- 21/27 [keras]\n",
      "   ------------------------------- -------- 21/27 [keras]\n",
      "   ------------------------------- -------- 21/27 [keras]\n",
      "   ------------------------------- -------- 21/27 [keras]\n",
      "   -------------------------------- ------- 22/27 [audioread]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ---------------------------------- ----- 23/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [librosa]\n",
      "   ------------------------------------- -- 25/27 [tf-keras]\n",
      "   ------------------------------------- -- 25/27 [tf-keras]\n",
      "   ------------------------------------- -- 25/27 [tf-keras]\n",
      "   ------------------------------------- -- 25/27 [tf-keras]\n",
      "   ------------------------------------- -- 25/27 [tf-keras]\n",
      "   ------------------------------------- -- 25/27 [tf-keras]\n",
      "   ------------------------------------- -- 25/27 [tf-keras]\n",
      "   ------------------------------------- -- 25/27 [tf-keras]\n",
      "   ------------------------------------- -- 25/27 [tf-keras]\n",
      "   ------------------------------------- -- 25/27 [tf-keras]\n",
      "   ------------------------------------- -- 25/27 [tf-keras]\n",
      "   ------------------------------------- -- 25/27 [tf-keras]\n",
      "   ------------------------------------- -- 25/27 [tf-keras]\n",
      "   ------------------------------------- -- 25/27 [tf-keras]\n",
      "   ------------------------------------- -- 25/27 [tf-keras]\n",
      "   ------------------------------------- -- 25/27 [tf-keras]\n",
      "   ------------------------------------- -- 25/27 [tf-keras]\n",
      "   ---------------------------------------- 27/27 [tensorflow_hub]\n",
      "\n",
      "Successfully installed absl-py-2.3.1 astunparse-1.6.3 audioop-lts-0.2.2 audioread-3.1.0 flatbuffers-25.9.23 gast-0.6.0 google_pasta-0.2.0 grpcio-1.76.0 keras-3.12.0 libclang-18.1.1 librosa-0.11.0 ml_dtypes-0.5.3 namex-0.1.0 opt_einsum-3.4.0 optree-0.18.0 pooch-1.8.2 soundfile-0.13.1 soxr-1.0.0 standard-aifc-3.13.0 standard-chunk-3.13.0 standard-sunau-3.13.0 tensorboard-2.20.0 tensorboard-data-server-0.7.2 tensorflow-2.20.0 tensorflow_hub-0.16.1 termcolor-3.2.0 tf-keras-2.20.1\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow tensorflow_hub librosa soundfile scikit-learn matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "139ca1fa-6c78-49a0-ac4f-748a91dd3479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Mrutyunjaya EM\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Mrutyunjaya EM\\anaconda3\\Lib\\site-packages\\tensorflow_hub\\resolver.py:120: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Mrutyunjaya EM\\anaconda3\\Lib\\site-packages\\tensorflow_hub\\resolver.py:120: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Mrutyunjaya EM\\anaconda3\\Lib\\site-packages\\tensorflow_hub\\module_v2.py:126: The name tf.saved_model.load_v2 is deprecated. Please use tf.compat.v2.saved_model.load instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Mrutyunjaya EM\\anaconda3\\Lib\\site-packages\\tensorflow_hub\\module_v2.py:126: The name tf.saved_model.load_v2 is deprecated. Please use tf.compat.v2.saved_model.load instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting or loading embeddings...\n",
      "Found classes: ['fire', 'no_fire']\n",
      "Processing fire: 1432 files\n",
      "Processing no_fire: 1438 files\n",
      "Saved embedding cache: embeddings_2C.npz\n",
      "Embedding shape: (2870, 1024)\n",
      "Train: (2009, 1024) Val: (430, 1024) Test: (431, 1024)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">524,800</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">65,664</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">258</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m524,800\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m65,664\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │           \u001b[38;5;34m258\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">590,722</span> (2.25 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m590,722\u001b[0m (2.25 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">590,722</span> (2.25 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m590,722\u001b[0m (2.25 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 - 2s - 35ms/step - accuracy: 0.9159 - loss: 0.2095 - val_accuracy: 0.9581 - val_loss: 0.0963\n",
      "Epoch 2/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 - 0s - 7ms/step - accuracy: 0.9617 - loss: 0.1026 - val_accuracy: 0.9698 - val_loss: 0.0747\n",
      "Epoch 3/30\n",
      "63/63 - 0s - 6ms/step - accuracy: 0.9726 - loss: 0.0745 - val_accuracy: 0.9674 - val_loss: 0.0879\n",
      "Epoch 4/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 - 0s - 7ms/step - accuracy: 0.9746 - loss: 0.0625 - val_accuracy: 0.9628 - val_loss: 0.0609\n",
      "Epoch 5/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 - 0s - 7ms/step - accuracy: 0.9746 - loss: 0.0617 - val_accuracy: 0.9721 - val_loss: 0.0528\n",
      "Epoch 6/30\n",
      "63/63 - 0s - 6ms/step - accuracy: 0.9816 - loss: 0.0474 - val_accuracy: 0.9721 - val_loss: 0.0557\n",
      "Epoch 7/30\n",
      "63/63 - 0s - 6ms/step - accuracy: 0.9836 - loss: 0.0623 - val_accuracy: 0.9698 - val_loss: 0.0564\n",
      "Epoch 8/30\n",
      "63/63 - 0s - 6ms/step - accuracy: 0.9831 - loss: 0.0431 - val_accuracy: 0.9767 - val_loss: 0.0565\n",
      "Epoch 9/30\n",
      "63/63 - 0s - 6ms/step - accuracy: 0.9816 - loss: 0.0405 - val_accuracy: 0.9698 - val_loss: 0.0637\n",
      "Epoch 10/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 - 0s - 7ms/step - accuracy: 0.9856 - loss: 0.0360 - val_accuracy: 0.9884 - val_loss: 0.0470\n",
      "Epoch 11/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 - 0s - 7ms/step - accuracy: 0.9890 - loss: 0.0296 - val_accuracy: 0.9837 - val_loss: 0.0424\n",
      "Epoch 12/30\n",
      "63/63 - 0s - 6ms/step - accuracy: 0.9861 - loss: 0.0332 - val_accuracy: 0.9837 - val_loss: 0.0573\n",
      "Epoch 13/30\n",
      "63/63 - 0s - 6ms/step - accuracy: 0.9905 - loss: 0.0325 - val_accuracy: 0.9767 - val_loss: 0.0588\n",
      "Epoch 14/30\n",
      "63/63 - 0s - 6ms/step - accuracy: 0.9890 - loss: 0.0280 - val_accuracy: 0.9791 - val_loss: 0.0620\n",
      "Epoch 15/30\n",
      "63/63 - 0s - 6ms/step - accuracy: 0.9890 - loss: 0.0245 - val_accuracy: 0.9814 - val_loss: 0.0600\n",
      "Epoch 16/30\n",
      "63/63 - 0s - 6ms/step - accuracy: 0.9930 - loss: 0.0219 - val_accuracy: 0.9814 - val_loss: 0.0502\n",
      "\n",
      "Test Accuracy: 0.9860788583755493\n",
      "\n",
      "Saved model: fire_classifier.h5\n",
      "Saved label map: label_map.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import librosa\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras import layers, models, callbacks\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# CONFIG\n",
    "# -------------------------------------------------------\n",
    "DATA_DIR = \"2C\"                       # dataset folder\n",
    "EMBED_CACHE = \"embeddings_2C.npz\"    # cache file\n",
    "SAMPLE_RATE = 16000\n",
    "EPOCHS = 30\n",
    "BATCH_SIZE = 32\n",
    "SEED = 42\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# Load YAMNet (full version for training on laptop)\n",
    "# -------------------------------------------------------\n",
    "YAMNET_MODEL = \"https://tfhub.dev/google/yamnet/1\"\n",
    "yamnet = hub.load(YAMNET_MODEL)   # full YAMNet TF model\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# Helper: load wav & resample to 16 kHz mono\n",
    "# -------------------------------------------------------\n",
    "def load_audio(path, sr=SAMPLE_RATE):\n",
    "    wav, orig_sr = librosa.load(path, sr=None, mono=True)\n",
    "    if orig_sr != sr:\n",
    "        wav = librosa.resample(wav, orig_sr, sr)\n",
    "    return wav.astype(np.float32)\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# Extract embeddings (or load cached)\n",
    "# -------------------------------------------------------\n",
    "def build_or_load_embeddings():\n",
    "    if os.path.exists(EMBED_CACHE):\n",
    "        print(\"Loading cached embeddings:\", EMBED_CACHE)\n",
    "        data = np.load(EMBED_CACHE, allow_pickle=True)\n",
    "        return data[\"X\"], data[\"y\"], data[\"paths\"]\n",
    "\n",
    "    X_list, y_list, paths_list = [], [], []\n",
    "\n",
    "    classes = sorted(os.listdir(DATA_DIR))\n",
    "    print(\"Found classes:\", classes)\n",
    "\n",
    "    for cls in classes:\n",
    "        cls_path = os.path.join(DATA_DIR, cls)\n",
    "        if not os.path.isdir(cls_path):\n",
    "            continue\n",
    "\n",
    "        wav_files = glob.glob(os.path.join(cls_path, \"*.wav\"))\n",
    "        print(f\"Processing {cls}: {len(wav_files)} files\")\n",
    "\n",
    "        for p in wav_files:\n",
    "            try:\n",
    "                audio = load_audio(p)\n",
    "                # Run YAMNet\n",
    "                scores, embeddings, spect = yamnet(audio)\n",
    "                emb_np = embeddings.numpy()\n",
    "\n",
    "                # Mean pool over frames → (1024,)\n",
    "                emb_mean = np.mean(emb_np, axis=0)\n",
    "\n",
    "                X_list.append(emb_mean)\n",
    "                y_list.append(cls)\n",
    "                paths_list.append(p)\n",
    "            except Exception as e:\n",
    "                print(\"Error processing\", p, e)\n",
    "\n",
    "    X = np.vstack(X_list).astype(np.float32)\n",
    "    y = np.array(y_list)\n",
    "    paths = np.array(paths_list)\n",
    "\n",
    "    np.savez(EMBED_CACHE, X=X, y=y, paths=paths)\n",
    "    print(\"Saved embedding cache:\", EMBED_CACHE)\n",
    "\n",
    "    return X, y, paths\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# MLP classifier model\n",
    "# -------------------------------------------------------\n",
    "def build_classifier(input_dim, num_classes):\n",
    "    inp = layers.Input(shape=(input_dim,))\n",
    "    x = layers.Dense(512, activation='relu')(inp)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = layers.Dense(128, activation='relu')(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    out = layers.Dense(num_classes, activation='softmax')(x)\n",
    "    return models.Model(inp, out)\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# Main training pipeline\n",
    "# -------------------------------------------------------\n",
    "def main():\n",
    "    print(\"Extracting or loading embeddings...\")\n",
    "    X, y, paths = build_or_load_embeddings()\n",
    "    print(\"Embedding shape:\", X.shape)\n",
    "\n",
    "    # Encode labels\n",
    "    le = LabelEncoder()\n",
    "    y_enc = le.fit_transform(y)\n",
    "\n",
    "    # Split: 70 / 15 / 15\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "        X, y_enc, test_size=0.30, stratify=y_enc, random_state=SEED\n",
    "    )\n",
    "    X_val, X_test, y_val, y_test = train_test_split(\n",
    "        X_temp, y_temp, test_size=0.50, stratify=y_temp, random_state=SEED\n",
    "    )\n",
    "\n",
    "    print(\"Train:\", X_train.shape, \"Val:\", X_val.shape, \"Test:\", X_test.shape)\n",
    "\n",
    "    # Build model\n",
    "    model = build_classifier(1024, len(le.classes_))\n",
    "    model.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "    model.summary()\n",
    "\n",
    "    # Callbacks\n",
    "    es = callbacks.EarlyStopping(patience=5, restore_best_weights=True)\n",
    "    ck = callbacks.ModelCheckpoint(\"fire_classifier.h5\", save_best_only=True)\n",
    "\n",
    "    # Train\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=EPOCHS,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        callbacks=[es, ck],\n",
    "        verbose=2\n",
    "    )\n",
    "\n",
    "    # Evaluate on test set\n",
    "    test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print(\"\\nTest Accuracy:\", test_acc)\n",
    "\n",
    "    # Save label mapping\n",
    "    with open(\"label_map.json\", \"w\") as f:\n",
    "        json.dump({\"classes\": le.classes_.tolist()}, f)\n",
    "\n",
    "    print(\"\\nSaved model: fire_classifier.h5\")\n",
    "    print(\"Saved label map: label_map.json\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "514786d1-6d39-4344-bc0d-df0bb3e62e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\MRUTYU~1\\AppData\\Local\\Temp\\tmpiweg0sl8\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\MRUTYU~1\\AppData\\Local\\Temp\\tmpiweg0sl8\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at 'C:\\Users\\MRUTYU~1\\AppData\\Local\\Temp\\tmpiweg0sl8'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 1024), dtype=tf.float32, name='input_layer')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 2), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  2584590803088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2584590805200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2584590805008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2584590806352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2584590804816: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2584590801168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "✔ Saved fire_classifier.tflite\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.models.load_model(\"fire_classifier.h5\")\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open(\"fire_classifier.tflite\", \"wb\") as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "print(\"✔ Saved fire_classifier.tflite\")\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023f520b-760f-4d7b-959f-18e844c1a268",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
